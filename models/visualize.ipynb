{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb44307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: 配置（修改这里切换模型）\n",
    "CONFIG_PATH = \"../configs/scheme_d.yaml\"\n",
    "CHECKPOINT_PATH = \"../checkpoints/scheme_d/best_model.pt\"\n",
    "N_SAMPLES = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "bynajwlxbrp",
   "source": "# Cell 0: 独立PPG分析（不需要加载模型，可以直接运行这个cell）\n# 分析视频RGB信号是否包含有效的心跳节律信息\n\n%matplotlib inline\nimport os\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom scipy import signal as scipy_signal\nimport matplotlib.pyplot as plt\nimport json\n\n# 找到项目根目录\n_cwd = os.getcwd()\nif os.path.exists(os.path.join(_cwd, \"training_data/samples\")):\n    ROOT = _cwd\nelif os.path.exists(os.path.join(_cwd, \"../training_data/samples\")):\n    ROOT = os.path.dirname(_cwd)\nelse:\n    ROOT = _cwd\nos.chdir(ROOT)\nprint(f\"Project root: {ROOT}\")\n\ndef get_video_info(video_path):\n    cap = cv2.VideoCapture(video_path)\n    info = {\n        \"frame_count\": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n        \"fps\": cap.get(cv2.CAP_PROP_FPS),\n        \"width\": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n        \"height\": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n    }\n    info[\"file_size_mb\"] = os.path.getsize(video_path) / (1024 * 1024)\n    info[\"duration_s\"] = info[\"frame_count\"] / info[\"fps\"] if info[\"fps\"] > 0 else 0\n    info[\"bitrate_kbps\"] = (info[\"file_size_mb\"] * 8 * 1024) / info[\"duration_s\"] if info[\"duration_s\"] > 0 else 0\n    cap.release()\n    return info\n\ndef extract_rgb_signal(video_path, max_frames=None):\n    cap = cv2.VideoCapture(video_path)\n    if max_frames is None:\n        max_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    rgb_signals = []\n    for _ in range(max_frames):\n        ret, frame = cap.read()\n        if not ret: break\n        rgb_signals.append([frame[:,:,2].mean(), frame[:,:,1].mean(), frame[:,:,0].mean()])\n    cap.release()\n    return np.array(rgb_signals)\n\ndef bandpass_filter(sig, fs, lowcut=0.7, highcut=4.0, order=3):\n    nyq = 0.5 * fs\n    b, a = scipy_signal.butter(order, [lowcut/nyq, highcut/nyq], btype='band')\n    return scipy_signal.filtfilt(b, a, sig)\n\ndef get_dominant_hr(sig, fs):\n    sig = sig - sig.mean()\n    freqs = np.fft.rfftfreq(len(sig), 1/fs)\n    fft_mag = np.abs(np.fft.rfft(sig))\n    hr_mask = (freqs >= 0.7) & (freqs <= 3.5)\n    if not hr_mask.any(): return None, 0, freqs, fft_mag\n    hr_freqs, hr_mags = freqs[hr_mask], fft_mag[hr_mask]\n    peak_idx = np.argmax(hr_mags)\n    snr = hr_mags[peak_idx]**2 / (hr_mags**2).sum()\n    return hr_freqs[peak_idx] * 60, snr, freqs, fft_mag\n\n# 分析\nsamples_dir = \"training_data/samples\"\npairs = sorted([d for d in os.listdir(samples_dir) if d.startswith(\"pair_\")])[:8]\n\nprint(\"=\"*70)\nprint(\"视频PPG信号分析 - 检查视频压缩是否影响心跳节律提取\")\nprint(\"=\"*70)\n\nfig, axes = plt.subplots(len(pairs), 4, figsize=(16, 2.5*len(pairs)))\n\nfor idx, pair in enumerate(pairs):\n    pair_dir = os.path.join(samples_dir, pair)\n    video_path = os.path.join(pair_dir, \"video_0.mp4\")\n    ecg_path = os.path.join(pair_dir, \"ecg.csv\")\n    meta_path = os.path.join(pair_dir, \"metadata.json\")\n    \n    vinfo = get_video_info(video_path)\n    fps = vinfo['fps']\n    \n    # 提取前10秒RGB信号\n    rgb = extract_rgb_signal(video_path, min(int(10 * fps), vinfo['frame_count']))\n    t = np.arange(len(rgb)) / fps\n    \n    # 带通滤波红色通道\n    red_norm = (rgb[:,0] - rgb[:,0].mean()) / (rgb[:,0].std() + 1e-8)\n    red_filt = bandpass_filter(red_norm, fps)\n    \n    # FFT检测心率\n    ppg_hr, snr, freqs, fft_mag = get_dominant_hr(red_filt, fps)\n    \n    # 读取标注心率\n    with open(meta_path) as f:\n        annotated_hr = json.load(f).get(\"heart_rate\")\n    \n    # 打印结果\n    if ppg_hr:\n        err = abs(ppg_hr - annotated_hr)\n        status = \"✓好\" if err < 10 else (\"△一般\" if err < 20 else \"✗差\")\n        print(f\"{pair}: {vinfo['bitrate_kbps']:.0f}kbps | PPG={ppg_hr:.0f} GT={annotated_hr} 误差={err:.0f} {status} | SNR={snr:.3f}\")\n    else:\n        print(f\"{pair}: {vinfo['bitrate_kbps']:.0f}kbps | 未检测到PPG | GT={annotated_hr}\")\n    \n    # 绘图\n    ax = axes[idx]\n    ax[0].plot(t, rgb[:,0], 'r-', lw=0.5); ax[0].set_ylabel(pair[-4:]); ax[0].grid(True, alpha=0.3)\n    ax[1].plot(t, red_filt, 'r-', lw=0.5); ax[1].grid(True, alpha=0.3)\n    hr_mask = (freqs >= 0.5) & (freqs <= 4)\n    ax[2].plot(freqs[hr_mask]*60, fft_mag[hr_mask], 'b-')\n    if ppg_hr: ax[2].axvline(ppg_hr, color='r', ls='--', alpha=0.7)\n    if annotated_hr: ax[2].axvline(annotated_hr, color='g', ls=':', alpha=0.7)\n    ax[2].set_xlim(40, 150); ax[2].grid(True, alpha=0.3)\n    ecg = pd.read_csv(ecg_path)[\"ecg_counts_filt_monitor\"].values[:2500]\n    ax[3].plot(np.arange(len(ecg))/250, (ecg-ecg.mean())/(ecg.std()+1e-8), 'b-', lw=0.5); ax[3].grid(True, alpha=0.3)\n    \n    if idx == 0:\n        ax[0].set_title('Red Raw'); ax[1].set_title('Red Filtered'); ax[2].set_title('FFT (BPM)'); ax[3].set_title('ECG')\n    if idx == len(pairs)-1:\n        for a in ax: a.set_xlabel('Time (s)')\n\nplt.tight_layout()\nos.makedirs(\"eval_results/visualize\", exist_ok=True)\nplt.savefig(\"eval_results/visualize/ppg_quality_check.png\", dpi=150, bbox_inches='tight')\nprint(f\"\\n图片已保存: eval_results/visualize/ppg_quality_check.png\")\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"结论：如果大部分样本PPG心率与GT心率误差<10BPM，说明视频包含有效PPG信息\")\nprint(\"如果误差普遍>20BPM或SNR<0.05，说明视频压缩可能导致PPG信息丢失\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffaf7b4",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: 导入和初始化\n%matplotlib inline\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport yaml\nimport matplotlib.pyplot as plt\n\nfrom dataset import create_datasets\nfrom video_ecg_model import build_model\n\n# 不依赖 cwd：在多个可能的工作目录下查找 config 文件，确定项目根目录\n_cwd = os.getcwd()\n_config_name = os.path.basename(CONFIG_PATH)  # e.g. scheme_a.yaml\n_candidates = [\n    os.path.join(_cwd, CONFIG_PATH),\n    os.path.join(_cwd, \"models\", CONFIG_PATH),\n    os.path.join(_cwd, \"ECG\", \"configs\", _config_name),\n    os.path.join(_cwd, \"configs\", _config_name),\n]\nCONFIG_PATH_ABS = None\nfor p in _candidates:\n    p = os.path.abspath(p)\n    if os.path.isfile(p):\n        CONFIG_PATH_ABS = p\n        break\nif CONFIG_PATH_ABS is None:\n    raise FileNotFoundError(f\"Config not found. cwd={_cwd!r}, CONFIG_PATH={CONFIG_PATH!r}. Tried: {_candidates}\")\n# 项目根 = config 所在目录的上一级（configs/ 的父目录）\n_ROOT = os.path.dirname(os.path.dirname(CONFIG_PATH_ABS))\nos.chdir(_ROOT)\n# checkpoint 相对项目根（去掉开头的 ../ 或 ./，避免 join(ROOT, \"../checkpoints/...\") 跑到 ROOT 上一级）\n_checkpoint_rel = CHECKPOINT_PATH.lstrip(\"./\").lstrip(\"/\")\nCHECKPOINT_PATH_ABS = os.path.normpath(os.path.join(_ROOT, _checkpoint_rel))\nprint(f\"Project root: {_ROOT}\")\n\n# 提取 scheme 名称用于区分保存路径\nSCHEME_NAME = os.path.splitext(_config_name)[0]  # e.g. \"scheme_d\"\nSAVE_DIR = f\"eval_results/visualize/{SCHEME_NAME}\"\nos.makedirs(SAVE_DIR, exist_ok=True)\nprint(f\"Scheme: {SCHEME_NAME}, Save dir: {SAVE_DIR}\")\n\n# 加载配置\nwith open(CONFIG_PATH_ABS) as f:\n    cfg = yaml.safe_load(f)\n\n# 设备\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {device}\")\n\n# 加载模型\nmodel = build_model(cfg).to(device)\nckpt = torch.load(CHECKPOINT_PATH_ABS, map_location=device)\n# 兼容两种格式：纯 state_dict 或 {'model_state_dict': state_dict}\nstate_dict = ckpt[\"model_state_dict\"] if isinstance(ckpt, dict) and \"model_state_dict\" in ckpt else ckpt\nmodel.load_state_dict(state_dict)\nmodel.eval()\nprint(f\"Loaded: {CHECKPOINT_PATH_ABS}\")\n\n# 数据\nuse_imu = cfg.get(\"data\", {}).get(\"use_imu\", False)\n_, _, test_ds = create_datasets(cfg)\ntest_loader = torch.utils.data.DataLoader(\n    test_ds,\n    batch_size=cfg[\"train\"][\"batch_size\"],\n    shuffle=False,\n    num_workers=cfg.get(\"data\", {}).get(\"num_workers\", 0),\n)\nprint(f\"Use IMU: {use_imu}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: preds=(6, 2500), targets=(6, 2500)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: 获取预测结果\n",
    "@torch.no_grad()\n",
    "def get_predictions(model, dataloader, device, use_imu, max_samples=10):\n",
    "    preds, targets = [], []\n",
    "    for batch in dataloader:\n",
    "        if use_imu:\n",
    "            video, imu, ecg = batch\n",
    "            pred = model(video.to(device), imu.to(device)).cpu().numpy()\n",
    "        else:\n",
    "            video, ecg = batch\n",
    "            pred = model(video.to(device)).cpu().numpy()\n",
    "        preds.append(pred)\n",
    "        targets.append(ecg.numpy())\n",
    "        if sum(len(p) for p in preds) >= max_samples:\n",
    "            break\n",
    "    return np.concatenate(preds)[:max_samples], np.concatenate(targets)[:max_samples]\n",
    "\n",
    "preds, targets = get_predictions(model, test_loader, device, use_imu, N_SAMPLES)\n",
    "print(f\"Shape: preds={preds.shape}, targets={targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: 单样本对比（修改 idx 查看不同样本）\nidx = 0  # <-- 改这里切换样本\nfs = 250\nt = np.arange(preds.shape[1]) / fs\n\npred, target = preds[idx], targets[idx]\nr = np.corrcoef(pred, target)[0, 1]\nrmse = np.sqrt(np.mean((pred - target) ** 2))\n\nfig, axes = plt.subplots(3, 1, figsize=(14, 7), sharex=True)\naxes[0].plot(t, target, 'b', lw=0.8)\naxes[0].set_ylabel('Ground Truth')\naxes[0].set_title(f'Sample {idx} | RMSE={rmse:.4f} | Pearson r={r:.4f}')\n\naxes[1].plot(t, pred, 'r', lw=0.8)\naxes[1].set_ylabel('Predicted')\n\naxes[2].plot(t, target, 'b', lw=0.8, alpha=0.7, label='GT')\naxes[2].plot(t, pred, 'r', lw=0.8, alpha=0.7, label='Pred')\naxes[2].set_ylabel('Overlay')\naxes[2].set_xlabel('Time (s)')\naxes[2].legend()\n\nfor ax in axes:\n    ax.grid(True, alpha=0.3)\nplt.tight_layout()\n_save = f\"{SAVE_DIR}/sample_single.png\"\nplt.savefig(_save, dpi=120, bbox_inches=\"tight\")\nprint(\"Saved:\", os.path.abspath(_save))\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: 放大查看细节（修改 start_sec 查看不同时间段）\nstart_sec = 2  # <-- 改这里\nduration = 3\n\nstart, end = int(start_sec * fs), int((start_sec + duration) * fs)\nt_zoom = t[start:end]\n\nplt.figure(figsize=(14, 4))\nplt.plot(t_zoom, target[start:end], 'b', lw=1.2, label='Ground Truth')\nplt.plot(t_zoom, pred[start:end], 'r--', lw=1.2, label='Predicted')\nplt.xlabel('Time (s)')\nplt.ylabel('ECG')\nplt.title(f'Sample {idx}: Zoomed {start_sec}-{start_sec+duration}s')\nplt.legend()\nplt.grid(True, alpha=0.3)\n_save = f\"{SAVE_DIR}/sample_zoom.png\"\nplt.savefig(_save, dpi=120, bbox_inches=\"tight\")\nprint(\"Saved:\", os.path.abspath(_save))\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: 所有样本概览\nfig, axes = plt.subplots(N_SAMPLES, 1, figsize=(14, 2.5 * N_SAMPLES), sharex=True)\nfor i in range(N_SAMPLES):\n    r = np.corrcoef(preds[i], targets[i])[0, 1]\n    axes[i].plot(t, targets[i], 'b', lw=0.6, alpha=0.7, label='GT')\n    axes[i].plot(t, preds[i], 'r', lw=0.6, alpha=0.7, label='Pred')\n    axes[i].set_ylabel(f'#{i}')\n    axes[i].set_title(f'r={r:.3f}', loc='right', fontsize=10)\n    axes[i].grid(True, alpha=0.3)\n    if i == 0:\n        axes[i].legend(loc='upper right')\naxes[-1].set_xlabel('Time (s)')\nplt.suptitle(f'All Samples Overview ({SCHEME_NAME})')\nplt.tight_layout()\n_save = f\"{SAVE_DIR}/all_samples.png\"\nplt.savefig(_save, dpi=120, bbox_inches=\"tight\")\nprint(\"Saved:\", os.path.abspath(_save))\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-sample metrics:\n",
      "----------------------------------------\n",
      "Sample 0: RMSE=0.9727, MAE=0.5632, r=0.0144\n",
      "Sample 1: RMSE=0.9865, MAE=0.5728, r=-0.1462\n",
      "Sample 2: RMSE=0.9949, MAE=0.5833, r=-0.2011\n",
      "Sample 3: RMSE=0.9976, MAE=0.5885, r=-0.1713\n",
      "Sample 4: RMSE=1.0252, MAE=0.5900, r=-0.1200\n",
      "Sample 5: RMSE=1.0412, MAE=0.6001, r=-0.1628\n",
      "----------------------------------------\n",
      "Mean RMSE: 1.0030\n",
      "Mean r:    -0.1311\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: 汇总指标\n",
    "print(\"Per-sample metrics:\")\n",
    "print(\"-\" * 40)\n",
    "for i in range(N_SAMPLES):\n",
    "    r = np.corrcoef(preds[i], targets[i])[0, 1]\n",
    "    rmse = np.sqrt(np.mean((preds[i] - targets[i]) ** 2))\n",
    "    mae = np.mean(np.abs(preds[i] - targets[i]))\n",
    "    print(f\"Sample {i}: RMSE={rmse:.4f}, MAE={mae:.4f}, r={r:.4f}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Mean RMSE: {np.mean([np.sqrt(np.mean((preds[i]-targets[i])**2)) for i in range(N_SAMPLES)]):.4f}\")\n",
    "print(f\"Mean r:    {np.mean([np.corrcoef(preds[i], targets[i])[0,1] for i in range(N_SAMPLES)]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4i4hokzog7c",
   "source": "# Cell 8: 分析视频RGB信号与ECG心率的关系\n# 检查视频压缩是否导致PPG信息丢失\n\nimport cv2\nfrom scipy import signal as scipy_signal\nfrom scipy.stats import pearsonr\nimport json\n\ndef get_video_info(video_path):\n    \"\"\"获取视频信息\"\"\"\n    cap = cv2.VideoCapture(video_path)\n    info = {\n        \"frame_count\": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n        \"fps\": cap.get(cv2.CAP_PROP_FPS),\n        \"width\": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n        \"height\": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n    }\n    info[\"file_size_mb\"] = os.path.getsize(video_path) / (1024 * 1024)\n    info[\"duration_s\"] = info[\"frame_count\"] / info[\"fps\"] if info[\"fps\"] > 0 else 0\n    info[\"bitrate_kbps\"] = (info[\"file_size_mb\"] * 8 * 1024) / info[\"duration_s\"] if info[\"duration_s\"] > 0 else 0\n    cap.release()\n    return info\n\ndef extract_rgb_signal(video_path, max_frames=None):\n    \"\"\"从视频提取RGB通道均值\"\"\"\n    cap = cv2.VideoCapture(video_path)\n    if max_frames is None:\n        max_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    rgb_signals = []\n    for _ in range(max_frames):\n        ret, frame = cap.read()\n        if not ret:\n            break\n        # BGR -> RGB\n        rgb_signals.append([frame[:,:,2].mean(), frame[:,:,1].mean(), frame[:,:,0].mean()])\n    cap.release()\n    return np.array(rgb_signals)\n\ndef bandpass_filter(sig, fs, lowcut=0.7, highcut=4.0, order=3):\n    \"\"\"带通滤波 (0.7-4Hz = 42-240 BPM)\"\"\"\n    nyq = 0.5 * fs\n    b, a = scipy_signal.butter(order, [lowcut/nyq, highcut/nyq], btype='band')\n    return scipy_signal.filtfilt(b, a, sig)\n\ndef analyze_periodicity(sig, fs):\n    \"\"\"FFT分析心率\"\"\"\n    sig = sig - sig.mean()\n    freqs = np.fft.rfftfreq(len(sig), 1/fs)\n    fft_mag = np.abs(np.fft.rfft(sig))\n    \n    # 心率范围 0.7-3.5 Hz = 42-210 BPM\n    hr_mask = (freqs >= 0.7) & (freqs <= 3.5)\n    if not hr_mask.any():\n        return None, 0\n    \n    hr_freqs = freqs[hr_mask]\n    hr_mags = fft_mag[hr_mask]\n    peak_idx = np.argmax(hr_mags)\n    dominant_hr = hr_freqs[peak_idx] * 60\n    \n    # SNR\n    snr = hr_mags[peak_idx]**2 / (hr_mags**2).sum()\n    return dominant_hr, snr\n\n# 分析前5个样本\nsamples_dir = \"training_data/samples\"\npairs = sorted([d for d in os.listdir(samples_dir) if d.startswith(\"pair_\")])[:5]\n\nprint(\"=\"*70)\nprint(\"视频PPG信号与ECG心率关系分析\")\nprint(\"=\"*70)\n\nfig, axes = plt.subplots(len(pairs), 4, figsize=(16, 3*len(pairs)))\nresults = []\n\nfor idx, pair in enumerate(pairs):\n    pair_dir = os.path.join(samples_dir, pair)\n    video_path = os.path.join(pair_dir, \"video_0.mp4\")\n    ecg_path = os.path.join(pair_dir, \"ecg.csv\")\n    meta_path = os.path.join(pair_dir, \"metadata.json\")\n    \n    # 视频信息\n    vinfo = get_video_info(video_path)\n    fps = vinfo['fps']\n    \n    print(f\"\\n{pair}: {vinfo['file_size_mb']:.1f}MB, {vinfo['bitrate_kbps']:.0f}kbps, {vinfo['width']}x{vinfo['height']}\")\n    \n    # 提取RGB信号 (10秒)\n    max_frames = min(int(10 * fps), vinfo['frame_count'])\n    rgb = extract_rgb_signal(video_path, max_frames)\n    t_video = np.arange(len(rgb)) / fps\n    \n    # 红色通道滤波\n    red_norm = (rgb[:,0] - rgb[:,0].mean()) / (rgb[:,0].std() + 1e-8)\n    red_filt = bandpass_filter(red_norm, fps, 0.7, 4.0)\n    \n    # PPG心率\n    ppg_hr, snr = analyze_periodicity(red_filt, fps)\n    \n    # ECG\n    ecg_df = pd.read_csv(ecg_path)\n    ecg = ecg_df[\"ecg_counts_filt_monitor\"].values[:2500]\n    t_ecg = np.arange(len(ecg)) / 250\n    \n    # 标注心率\n    with open(meta_path) as f:\n        meta = json.load(f)\n    annotated_hr = meta.get(\"heart_rate\")\n    \n    if ppg_hr:\n        error = abs(ppg_hr - annotated_hr)\n        status = \"✓\" if error < 10 else (\"△\" if error < 20 else \"✗\")\n        print(f\"  PPG心率: {ppg_hr:.1f} BPM, 标注: {annotated_hr} BPM, 误差: {error:.1f} {status}\")\n    else:\n        print(f\"  PPG心率: 未检测到, 标注: {annotated_hr} BPM\")\n    print(f\"  信号SNR: {snr:.3f}, RGB std: R={rgb[:,0].std():.2f}, G={rgb[:,1].std():.2f}, B={rgb[:,2].std():.2f}\")\n    \n    results.append({'pair': pair, 'ppg_hr': ppg_hr, 'annotated_hr': annotated_hr, 'snr': snr, 'bitrate': vinfo['bitrate_kbps']})\n    \n    # 绘图\n    ax = axes[idx] if len(pairs) > 1 else axes\n    \n    # 红色原始\n    ax[0].plot(t_video, rgb[:,0], 'r-', lw=0.5)\n    ax[0].set_ylabel(f'{pair}\\nRed')\n    if idx == 0: ax[0].set_title('Red Channel (Raw)')\n    ax[0].grid(True, alpha=0.3)\n    \n    # 红色滤波\n    ax[1].plot(t_video, red_filt, 'r-', lw=0.5)\n    ax[1].set_ylabel('Red Filt')\n    if idx == 0: ax[1].set_title('Red (0.7-4Hz BP)')\n    ax[1].grid(True, alpha=0.3)\n    \n    # FFT\n    freqs = np.fft.rfftfreq(len(red_filt), 1/fps)\n    fft_mag = np.abs(np.fft.rfft(red_filt))\n    hr_mask = (freqs >= 0.5) & (freqs <= 4)\n    ax[2].plot(freqs[hr_mask]*60, fft_mag[hr_mask], 'b-')\n    if ppg_hr: ax[2].axvline(ppg_hr, color='r', linestyle='--', alpha=0.7, label=f'PPG: {ppg_hr:.0f}')\n    if annotated_hr: ax[2].axvline(annotated_hr, color='g', linestyle=':', alpha=0.7, label=f'GT: {annotated_hr}')\n    ax[2].set_xlim(40, 150)\n    ax[2].legend(fontsize=8)\n    if idx == 0: ax[2].set_title('FFT (BPM)')\n    ax[2].grid(True, alpha=0.3)\n    \n    # ECG\n    ecg_norm = (ecg - ecg.mean()) / (ecg.std() + 1e-8)\n    ax[3].plot(t_ecg, ecg_norm, 'b-', lw=0.5)\n    if idx == 0: ax[3].set_title('ECG')\n    ax[3].grid(True, alpha=0.3)\n    \n    if idx == len(pairs) - 1:\n        for a in ax: a.set_xlabel('Time (s)')\n\nplt.tight_layout()\n_save = f\"{SAVE_DIR}/ppg_ecg_analysis.png\"\nplt.savefig(_save, dpi=150, bbox_inches='tight')\nprint(f\"\\n图片已保存: {_save}\")\nplt.show()\n\n# 汇总\nprint(\"\\n\" + \"=\"*70)\nprint(\"汇总\")\nprint(\"=\"*70)\nvalid = [r for r in results if r['ppg_hr']]\nif valid:\n    errors = [abs(r['ppg_hr'] - r['annotated_hr']) for r in valid]\n    print(f\"有效PPG心率检测: {len(valid)}/{len(results)}\")\n    print(f\"PPG-ECG心率误差: 平均={np.mean(errors):.1f} BPM\")\n    print(f\"平均码率: {np.mean([r['bitrate'] for r in results]):.0f} kbps\")\n    print(f\"平均SNR: {np.mean([r['snr'] for r in results]):.3f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anoshift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}