# 完整行动计划：ECG 重建项目

> 制定日期：2026-02-08
> 基于数据质量分析结果和当前实验进展

---

## 我对 9.2-9.4 建议的评价

### 完全同意的部分

1. **暂停 IMU/Audio 融合开发** — 100% 同意。当前最大瓶颈是 PPG 信号质量，多模态融合在单模态不 work 时毫无意义。
2. **在高质量子集上训练验证模型** — 非常好的策略。42 个 |r|>0.3 的样本足够做 proof-of-concept。
3. **锁定曝光是最关键的 App 修改** — 这是我们能做的收益最大的一件事。
4. **音频模态建议放弃（除非改硬件）** — 同意。手机麦克风的 PCG r=0.056，投入产出比太低。

### 需要修正/补充的部分

1. **"提高帧率至 60-120fps"** — **不建议作为优先项**。30fps 对 PPG 完全够用（心率 < 3Hz，Nyquist 只需 6fps）。提高帧率会增加文件大小和处理时间，收益不大。**锁定曝光的优先级比提高帧率高 100 倍**。
2. **"降低闪光灯亮度"** — 应该说"降低手电筒亮度"。当前代码设的是 `level: 1.0`（满功率），确实需要降到 0.1-0.3，但原因不是"降低闪光灯亮度"那么简单，而是**防止红色通道饱和到 255**。
3. **"在公开数据集预训练 video-to-PPG"** — 好想法，但要注意 UBFC-rPPG 和 PURE 是**非接触式 rPPG**（人脸视频），和你们的**接触式 PPG**（手指视频）在信号特性上差异很大。预训练可能迁移效果有限。更好的策略是在 BIDMC 上验证 PPG→ECG 架构本身。
4. **关于 IMU 的"胸部放置场景"** — 理论上对，但实际上和手指 PPG 采集是矛盾的（手机不能同时放胸口又让手指盖摄像头）。IMU 的实际价值是**运动伪迹检测**，而不是直接映射 ECG。

### 新增建议

5. **跳过视频的二次压缩**：当前 App 录制 MOV 后用 `AVAssetExportPresetMediumQuality` 重编码为 MP4，引入了额外的压缩损失。改用 `AVAssetExportPresetPassthrough` 可以零损失导出。
6. **同时输出每帧 RGB 均值 CSV**：PPG 分析只需要每帧的通道均值，直接输出 CSV 比解码视频更精确更快。

---

## 明天就要做的 Checklist

### 给 App 开发同学的任务（明天沟通）

把 `docs/app_modification_guide.md` 发给他，重点沟通以下内容：

- [ ] **P0-1：锁定曝光/ISO/白平衡**
  - 修改 `CameraService.swift`
  - 在录制开始前调用 `lockExposureForPPG()`
  - 推荐使用"先自动后锁定"方案（利用倒计时 3 秒让自动曝光稳定）
  - **这是最关键的一个修改，预期 PPG 信噪比提升 10-20 倍**

- [ ] **P0-2：手电筒亮度从 1.0 降到 0.1**
  - `CameraService.swift` 第 282 行
  - 一行代码的修改，但很重要（避免红通道饱和）

- [ ] **P0-3：视频导出改为 Passthrough**
  - `CameraService.swift` 中 `convertToMP4()` 方法
  - 将 `settingsService.videoQuality` 改为 `AVAssetExportPresetPassthrough`
  - 避免二次压缩造成的质量损失

- [ ] **P1：让开发同学评估实时 PPG 质量反馈的可行性**
  - 需要新增 `AVCaptureVideoDataOutput`
  - 在录制界面显示信号质量指示器
  - 如果短期内来不及做，可以先做上面 3 个 P0

### 自己的任务（今天/明天）

- [ ] 检查 Round 3 实验结果（bandpass + temporal_norm）
- [ ] 如果 Round 3 没跑完，在 42 个高质量样本上跑 Scheme E 验证
- [ ] 准备 BIDMC baseline 数据和代码

---

## 硬件采购建议

### 结论：**暂不建议购买心音设备**

理由：
1. 当前音频 PCG 的 r=0.056，即使换了好的麦克风，PCG→ECG 的映射本身就非常困难（心音反映的是瓣膜运动，而 ECG 反映的是电活动，两者关系间接）
2. 先把 PPG→ECG 做到 r>0.5，再考虑增加模态
3. 采购硬件→等待到货→集成到 App→重新采集数据→训练验证，整个链路太长
4. **如果 PPG 锁定曝光后效果好，单模态就够了**

### 如果确实想买（备选方案）

| 方案 | 产品 | 价格 | 推荐度 |
|------|------|------|--------|
| 最便宜 | MEMS 麦克风模块 (SPH0645/ADMP401) + Arduino | ~50-100 RMB | 低（需要自己做电路和 App 集成） |
| 性价比最高 | Stemoscope II 无线听诊器 | ~1500-2000 RMB | 中（蓝牙连 iPhone，有现成 App，但数据导出可能受限） |
| 最专业 | Mintti Smartho-D2 | ~3000 RMB | 中高（FDA 认证，免费 App，数据可导出） |
| 最简单 | 淘宝搜"电子听诊器 蓝牙" | 200-800 RMB | 低（质量参差不齐） |

**如果非要买一个，我推荐 Stemoscope II**：
- 蓝牙无线，贴在胸口即可
- 有自己的 iOS App（Stemoscope App）可以录音导出
- 但注意：需要和你们的 DubCamera App 做时间同步，这是额外的开发工作

**更实际的方案**：
- 在 iPhone 上录制时，让受试者把手机麦克风贴近胸口（比如手机放在桌上，受试者前倾贴胸）
- 采集几段对比数据，先评估手机麦克风在近距离下能否听到心音
- 如果能听到 → 软件方案足够
- 如果听不到 → 再考虑买硬件

---

## 短期计划（本周 ~ 下周）

### 本周（2月8-14日）

| 天数 | 任务 | 负责 | 输出 |
|------|------|------|------|
| Day 1 (2/9) | 和 App 开发同学沟通修改需求 | 你 | 确认修改方案，同步 guide 文档 |
| Day 1-3 | App 修改：锁定曝光 + 降低手电筒 + Passthrough | App 同学 | 新版 App |
| Day 1 | 检查 Round 3 实验结果 | 你/服务器 | 确认 bandpass 是否有效 |
| Day 2-3 | 在 42 个高质量样本上训练 Scheme E | 你/服务器 | 模型能力上限验证 |
| Day 2-3 | BIDMC baseline 训练 | 你/服务器 | PPG→ECG 架构验证 |
| Day 4-5 | 新版 App 出来后，采集 5-10 个对比样本 | 你 | 验证锁定曝光的效果 |
| Day 5-7 | 对比新旧数据的 PPG 质量指标 | 你 | 量化改善幅度 |

### 决策点（第 7 天）

```
Round 3 结果（bandpass 预处理）:
├── r > 0.2 → 信号存在，预处理有效 → 继续
├── r ≈ 0   → 信号太弱，必须等新 App 采集 → 转向 BIDMC 验证
└── 部分方案 r > 0.2 → 识别最有效的方案，集中优化

BIDMC baseline:
├── r > 0.7 → 模型架构 OK，问题完全在数据质量 → 全力改善数据
├── r = 0.3-0.7 → 模型需要调优，但基本可行 → 同时改数据和模型
└── r < 0.3 → 模型架构有问题 → 检查 PPG2ECG 实现

新 App 采集的数据:
├── 红通道漂移 < 2 units → 锁定曝光成功 → 进入正式采集
├── 红通道漂移仍然 > 10 units → 锁定失败 → 检查 App 代码
└── 红通道均值 > 245 或 < 50 → 手电筒亮度需要调整
```

---

## 中期计划（2-4 周）

### 前提：锁定曝光的新 App 已经就绪

| 周 | 任务 | 目标 |
|---|------|------|
| 第 2 周 | 用新 App 采集 50-100 个高质量样本 | 建立新数据集 V2 |
| 第 2 周 | 标准化采集协议（姿势、环境、时长） | 减少数据变异 |
| 第 2-3 周 | 在新数据上训练全部方案 (E, I, F, H) | 找到最优方案 |
| 第 3 周 | 消融实验：预处理 on/off, 不同方案对比 | 量化每个组件的贡献 |
| 第 3-4 周 | 如果单模态 r > 0.5 → 考虑加入 IMU | 多模态融合 |
| 第 4 周 | 撰写实验结果报告 | 阶段性总结 |

### 新数据采集 V2 协议

```
环境：室内安静，避免日光灯闪烁（用自然光或 LED 灯）
姿势：坐姿，前臂放桌上，左手食指轻盖后置摄像头
App设置：
  - 曝光已锁定（App V2）
  - 手电筒 level = 0.1
  - 视频 Passthrough（无二次压缩）
  - 录制时长 180 秒
预热：按下录制后，前 5 秒为预热期（后处理自动丢弃）
每人采集：
  - 静息态 × 3 次
  - 餐后 × 2 次
  - 运动后（高抬腿 1 分钟）× 2 次
目标：10+ 受试者 × 7 次 = 70+ 样本
```

---

## 长期计划（1-3 个月）

| 阶段 | 任务 | 目标 |
|------|------|------|
| **模型优化** | Transfer learning: BIDMC 预训练 → 微调到自有数据 | r > 0.6 |
| **数据增强** | 时间 warping, 加噪, mixup, 减小步长 (5s→2s) | 训练数据量 ×3 |
| **多模态** | 在视频单模态 r > 0.5 后，加入 IMU cross-attention | r 进一步提升 |
| **音频评估** | 如果有硬件，评估 PCG 贡献 | 决定是否纳入 |
| **新架构** | PhysMamba, CardioGAN-style 对抗训练 | 探索上限 |
| **论文撰写** | 整理实验结果，对比 baseline | 发表成果 |

---

## 优先级总结（从最重要到最不重要）

```
第一层（立即做，影响最大）:
  1. App 锁定曝光          → PPG SNR ↑ 10-20x
  2. App 降低手电筒亮度     → 避免饱和
  3. App Passthrough 导出   → 避免二次压缩

第二层（本周做，验证方向）:
  4. Round 3 结果检查        → 确认 bandpass 是否有效
  5. 高质量子集训练          → 验证模型能力上限
  6. BIDMC baseline         → 验证 PPG→ECG 是否可行

第三层（下周做，如果第一层成功）:
  7. 用新 App 采集对比数据    → 验证改善效果
  8. 全方案训练对比          → 找最优方案

第四层（中期，如果第三层成功）:
  9. 大规模新数据采集 (V2)    → 建立高质量数据集
  10. Transfer learning      → 提升模型性能

第五层（长期，酌情考虑）:
  11. IMU 融合              → 多模态
  12. 音频融合              → 需要硬件改变
  13. 新架构探索            → PhysMamba, GAN
```
